# Cloud AutoScale - GCP 2019 Proactive Configuration
# ML-driven proactive autoscaling using trained forecasting models

# Mode: "synthetic" or "gcp_2019"
mode: "gcp_2019"

# Data configuration
data:
  # Path to processed Parquet files directory
  # This directory must contain cluster_level.parquet
  processed_dir: "data/processed"
  
  # Optional: Limit simulation duration in minutes
  # If not specified, all available data will be used
  # duration_minutes: 1440  # 24 hours

# Simulation configuration
simulation:
  # Time step size in minutes (should match data processing bucket size)
  step_minutes: 5
  
  # Minimum number of machines
  min_machines: 100
  
  # Maximum number of machines
  max_machines: 5000
  
  # Capacity per machine (in units)
  # For GCP data, this represents normalized capacity
  machine_capacity: 1
  
  # Cost per machine per hour (in dollars)
  # Adjust based on your cloud provider pricing
  cost_per_machine_per_hour: 0.05

# Autoscaler configuration
autoscaler:
  # Autoscaler type: "baseline" (reactive) or "proactive" (ML-driven)
  type: "proactive"
  
  # Scale up when utilization exceeds this threshold
  upper_threshold: 0.75
  
  # Scale down when utilization falls below this threshold
  lower_threshold: 0.45
  
  # Maximum machines to add/remove per scaling action
  max_scale_per_step: 25
  
  # Cooldown period in time steps (to prevent thrashing)
  cooldown_steps: 1
  
  # Proactive autoscaler parameters
  # Must be tuned based on model residuals
  safety_margin: 1.18          # Add 18% safety margin to forecasts
  history_window: 30           # Number of recent steps for forecasting
  model_run_dir: "latest"      # Use "latest" to auto-detect, or specify path like "results/run_20251123_175247"
  
  # Asymmetric scaling parameters
  down_cooldown_multiplier: 3  # Downscale cooldown is 3x longer than upscale
  downscale_confirmation: true # Require double-confirmation for downscale

# Output configuration
output:
  # Directory to save results
  directory: "results"

